# Restaurant AI Assistant

This assistant implements a local RAG-style system using LangChain and Llama 3 via Ollama to provide an offline-first analytics solution. It features a modular ETL pipeline that cleans raw CSV data to ensure data type consistency for accurate mathematical analysis. The core intelligence is a ReAct reasoning agent that parses natural language into executable Pandas commands, enabling automated inventory planning and sales trend identification. By hosting the solution locally, the architecture ensures complete data privacy for sensitive restaurant transactions and eliminates external API costs.

# How the Solution Works: Step-by-Step

**1. Data Preparation (ETL Layer)**
The solution begins by passing raw restaurant sales data through a modular cleaning pipeline.

- Standardization: The src/data_cleaning.py script converts string-based dates into Python datetime objects and ensures sales quantities are stored as floating-point numbers.

- Mathematical Integrity: This step is critical because it prevents the AI model from failing when it attempts to perform calculations like "sum" or "average" on raw text data.

**2. The ReAct Reasoning Loop (Brain Layer)**
Instead of just "guessing" an answer, the agent uses the ReAct (Reason + Act) framework.

- Thought: When you ask a question, the Llama 3 model first creates a plan (e.g., "I need to filter the data for last week and sum the quantities").

- Action: The agent then generates exact Pandas Python code to perform that task.

- Observation: The system executes that code on your cleaned_data.csv and feeds the results back to the model, which then translates the raw numbers into a clear English response.

**3. Local Privacy & Efficiency (Inference Layer)**
The entire process happens within your local environment using Ollama.

- Data Privacy: Because the model (Llama 3) is running on your machine, your restaurant's transaction data never leaves your computer or goes to a third-party server.

- Offline Capability: The system does not require an active internet connection to process queries once the model is downloaded, making it highly reliable for restaurant branch operations.

---

# Table of Contents

- [Overview](#overview)
- [Project Structure](#project-structure)
- [Pipeline Architecture](#pipeline-architecture)
- [Installation](#installation)
- [Usage](#usage)
- [Configuration](#configuration)
- [Pipeline Steps](#pipeline-steps)
- [Key Concepts](#key-concepts-for-students)
- [Dependencies](#dependencies)
- [Suggested Improvements for Production](#suggested-improvements-for-production)

---

## Overview

This project implements a secure, local-first AI analytics platform with:

- **Automated ETL Pipeline** - Raw sales data cleaning and standardization.

- **Local LLM Integration** - Privacy-focused reasoning using Llama 3 via Ollama.

- **ReAct Framework**- An agentic loop that translates English queries into executable Pandas code.

- **Dynamic Forecasting** - Inventory estimation based on historical consumption patterns.

- **Zero-API Architecture** - High-performance AI analysis without external cloud costs or data leaks.

---



## Project Structure

```
RESTAURANT AI ASSISTANT/
│
├── data/                             # Data storage layer
│   ├── raw/                          # Original restaurant transaction CSVs
│   └── processed/                    # Optimized data generated by the ETL pipeline
│
├── src/                              # Core source code
│   ├── __init__.py                  # Package marker for modular imports
│   ├── agent_setup.py                # LLM initialization & ReAct agent configuration
│   ├── data_cleaning.py              # ETL pipeline for data standardization
│   └── utils.py                      # Configuration & environment management
│
├── venv/                             # Python virtual environment
├── .env                              # Private environment variables
├── .gitignore                        # Secure file exclusion for Git
├── main.py                           # Application entry point & chat loop orchestrator
├── requirements.txt                  # Categorized project dependencies
└── README.md                         # This file
```

---

## Pipeline Architecture

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                      RESTAURANT AI ANALYST WORKFLOW                         │
└─────────────────────────────────────────────────────────────────────────────┘
                                      │
                                      ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│  PHASE 1: ETL DATA CLEANING                                                 │
│  ├── Parse datetime strings to Pandas objects                               │
│  ├── Clean currency symbols & handle null values                            │
│  └── Export optimized CSV for AI consumption                                │
└─────────────────────────────────────────────────────────────────────────────┘
                                      │
                                      ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│  PHASE 2: AGENTIC REASONING (ReAct Loop)                                    │
│  ├── Thought: Analyze manager's natural language request                    │
│  ├── Action: Generate specific Python/Pandas code                           │
│  └── Observation: Interpret numerical results from DataFrame                │
└─────────────────────────────────────────────────────────────────────────────┘
                                      │
                                      ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│  PHASE 3: MANAGER INSIGHTS                                                  │
│  ├── Top-selling items identification                                       │
│  ├── Inventory forecasting for upcoming week                                │
│  └── Day-of-week sales trend analysis                                       │
└─────────────────────────────────────────────────────────────────────────────┘
```

---

## Installation

### 1. Clone/Navigate to project

```bash
cd RESTAURANT_AI_ASSISTANT
```

### 2. Create virtual environment

```bash
python3 -m venv venv
```

### 3. Activate virtual environment

```bash
# On Windows
venv\Scripts\activate
```

### 4. Configure Local LLM (Ollama)

```bash
ollama run llama3
```

### 5. Install dependencies

```bash
pip install -r requirements.txt
```

---

## Usage

Launch the AI Analyst:

```bash
python main.py
```

---

## Configuration

All system rules and LLM instructions are managed in `src/agent_setup.py`.

### Critical ReAct Rules

- **Tool Restriction**: Agent is forced to use python_repl_ast for all calculations.

- **Error Recovery**: Automatically handles "pd not defined" or "timedelta missing" by self-correcting imports.

- **Formatting**: Strictly follows Thought -> Action -> Action Input -> Observation.

---

## Pipeline Steps

### Step 1: Data Cleaning (`src/data_cleaning.py`)

```python
# Standardizes raw restaurant data by validating types and removing artifacts:

from src.data_cleaning import clean_data
# Automated ETL process
clean_data(
    input_path="data/raw/restaurant_sales_raw.csv", 
    output_path="data/processed/cleaned_data.csv"
)

def clean_data(input_path, output_path):
    df['Date'] = pd.to_datetime(df['Date'])
    df['Quantity'] = pd.to_numeric(df['Quantity'])
    df.to_csv(output_path, index=False)
```

### Step 2: Agent Initialization (`src/agent_setup.py`)

```python
# Bridges the local Llama 3 model with the Pandas DataFrame using a specialized ReAct prompt.

from src.agent_setup import create_restaurant_agent

# Initialize the AI Analyst
agent = create_restaurant_agent("data/processed/cleaned_data.csv")

agent = create_pandas_dataframe_agent(
    llm, df, verbose=True, allow_dangerous_code=True,
    agent_executor_kwargs={"handle_parsing_errors": True}
)
```
---

## Key Concepts

### 1. Modular Architecture
The project separates the logic into ETL (data_cleaning.py), inference (agent_setup.py), and orchestration (main.py).

### 2. Local-First AI
By using Ollama, the project ensures that sensitive restaurant transaction data never leaves the local machine.

### 3. Self-Correcting Reasoning
The implementation utilizes LangChain's parsing error handlers to allow the LLM to learn from its own syntax mistakes in real-time.

---

## Dependencies

| Category | Package | Purpose |
|---|---|---|
| Core ML | pandas | Data manipulation & aggregation |
| AI Framework | langchain | Agent orchestration & ReAct logic |
| Local LLM | langchain-ollama | Local Llama 3 integration |
| Validation | pydantic | Data structure enforcement |
| Environment | python-dotenv | Config & security management |

---

## Suggested Improvements for Production

**Relational Database Integration**: Transition data storage from static CSV files to a relational database like MySQL. This enables the system to process real-time sales data from POS (Point of Sale) systems across multiple branches rather than relying on historical batch files.

**Business Logic Layer (Hybrid Reliability)**: Move critical calculations (weekly totals, trend detection) into predefined Python functions instead of relying entirely on LLM-generated code. This improves reliability and ensures the mathematical accuracy of your business KPIs.

**Query Safety & Guardrails**: Implement strict input validation using Pydantic and intent filters. This prevents the execution of unsafe code and blocks sensitive operations like data deletion or unauthorized system-level commands.

**Web-Based User Interface**: Develop a browser-based dashboard using Streamlit. This allows non-technical managers to interact with the AI assistant visually through automated charts and reports without needing terminal access.

**Conversation Memory & Context Tracking**: Add session memory so the assistant can handle follow-up questions. This allows the manager to perform comparative analysis, such as "Now compare that to the previous week," by maintaining context over time.

**Decision Intelligence Layer**: Enhance the assistant to move beyond reporting data and provide proactive recommendations. For example, the agent could suggest specific promotions for low-performing menu items or automatically adjust ingredient orders based on upcoming demand forecasts.